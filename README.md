Movies are a popular form of entertainment for people all over the world. When a movie is produced and its trailer is released, it is common for viewers to leave multiple com- ments on it, often making judgments based solely on the brief two-minute clip they have seen. These comments are believed to play a crucial role in determining the fate of the movie once it is released to the public.<br />
The impact of viewers’ comments on a movie’s prospects is significant, as they can influence others’ decision-making when it comes to choosing which films to watch. With the rise of social media and online forums, people have more platforms than ever before to express their opinions and influence others. Keeping this in mind we pro- pose to analyze these comments on the trailers and use them to predict the rating of the movie from the set of classes (good, medium, bad). Our aim is to understand and utilize these comments and see if these comments can be used to make noteworthy predictions.<br /><br />

<H2><b>Experiments</b></H2>
<b>Experiment 1:</b><br/>
We cleaned movie trailer comments to bag of words using the dictionary that was created with CountVectorizer with 4000 features on the movie reviews dataset. Then all these movies were sent to the saved sentiment analysis model and we got predictions if a particular trailer comment was pos- itive or negative. Then for every movie we found the count of these positive and negative comments and made a new dataset which included the name of the movie, number of positive comments, number of negative comments and the rating of all these movies.<br />
These movies have a rating between 0 to 10. How- ever, for our experiments we had to convert these ratings to classes Good, Average and Bad. The classes are distributed such that ratings 0- 5 fall in class ’Bad’, 5- 7 fall in class ’Average’ and 7- 10 fall in class ’Good’. We assume IMDB ratings is a good metric to define how good the movie is and hence used it for this classification.
We then divide our dataset of number of positive com- ments, number of negative comments and rating into train and test set in the ratio 8: 2. We then created a model with 2 hidden layers and train it to predict the rating based on the positive and negative comments. Finally, prediction accu- racy is calculated on the test set.<br />

<b>Experiment 2:</b><br/>
In the previous experiment our final model was given only two features to work with and hence, it could not learn much. Keeping this in mind we decided to change our approach and give it better features in the form of comments itself rather than the number of positive and negative comments.<br />
For the second experiment, we merged all the clean com- ments with the ratings. These ratings are again classified into ’Good’, ’Average’, ’Bad’. We now have a dataset with the movie title and each comment is assigned a rating. We then converted all these comments to bag of words using CountVectorizer with a maximum of 5000 features. To train these comments we again divided the dataset into train and test set with a 8:2 ratio. This split was done directly on the movie titles rather than the comments. Now all the com- ments that belonged to a particular movie title were sent to either the train set or the test set. <br />
We also implemented one more approach to this exper- iment where we treated all YouTube comments of a movie as a feature instead of labelling each comment individually. Finally, we used multiple machine learning models like a 2 hidden layer neural network, K-Nearest Neighbors, Naive Bayes, Logistic Regression, Support Vector Machines, Bag- ging and Boosting to evaluate which approach gave us bet- ter result and which model performed the best among the various machine learning models.<br />
<b>Experiment 3:</b><br/>
For the third experiment we once again calculated the number of positive and negative comments for every movie using the same process as in Experiment 1 and found the ratio of positive and negative comments on the movie’s YouTube trailer. We also converted the IMDB rating to the three classes as required. For this experiment we wanted to check if our new features created any signif- icant change in the already available methods to calculate the success of movies.<br />
To do this we first created a model which took multi- ple features of the movie like its genre, its run-time in min- utes, etc as input and gave predictions on its rating from the set {Good, Average, Bad}. After this we added our fea- tures,(i.e.) number of positive comments and negative com- ments to this existing set of comments and trained a new model and calculated its accuracy using the pre-existing fea- ture "Success" as the classification label. We experimented both the approaches with logistic regression and decision trees to see how different models perform.<br />

<h2><b>Results:</b><br/></h2>
<b>Experiment 1:</b> Our first experiment was to check if we could develop a relation between the performance of a movie and the count of positive negative comments on the movie’s YouTube trailer. Using the Sentiment Analysis we had developed, we classified the comments to positive and negative and used a Neural Network model to predict how the movie would perform based on the ratio of posi- tive and negative comments on the YouTube trailer of the movie. The model only gave us an accuracy of 60% hence no inference could be made from this approach.<br />
<b>Experiment 2:</b> Our second experiment was to determine if we could develop any relation between the comments and the movie performance. For this we classified the IMDB rating of the movie as good( > 7.0), average(5.1 -7.0) and bad(< 5.0). Here, we tried out two different approaches.<br />
Approach 1: The comments were treated as individuals and each comment of the movie was given the IMDB rat- ing classification of the movie as the label and the model was trained. Predictions were made on this model and we obtained an accuracy of only 53% using Neural Networks.<br />
Approach 2: Instead of treating the comment as indi- viduals we found it optimal to use the entire comments of the movie as input to the model for each movie. All the comments of a movie were combined as one and bag-of- words for this input was created and served as input to the model. We believe this provides more information to the model than the previous approach. Neural Network model provided an accuracy of 73% which was better than the pre- vious approach. Although we are unable to infer the perfor- mance of a movie with this approach we can clearly see that this was a better approach than the previous one.<br />
As this approach seemed to have better performance, we implemented the same approach using different machine learning models like Logistic Regression, Naive Bayes, Support Vector Machine (SVM), K- Nearest Neighbor(with nearest-neighbors=3), Bagging and Boosting. We inferred that Neural Network, Logistic Regression Bagging and Boosting performed con- siderably better than other models with Boosting perform- ing the best out of them all with an accuracy of 72%.<br />
We were curious and experimented how TF-IDF vector- izer would perform when compared to CountVectorizer and noticed that TF-IDF vectorizer couldn’t perform as good as the Count vectorizer. This could be because of multi- ple reasons such as frequency based representation being more informative than the IDF weighting. Another reason for this would be amplification of noisy words by the TF- IDF vectorizer which is not the same with CountVectorizer as YouTube comments are generally noisy.<br />
We also experimented with one more case i.e, we divided the ratings into 2 classes i.e, either good or bad with thresh- old kept at IMDB rating 6.8.<br />

We implemented this use case with different machine models, i.e, Neural Network, Naive Bayes, Logistic Regres- sion, KNN, Support Vector Machines, Bagging and Boost- ing. From the plot we can confirm that the Neural Network Model performed the best with an accuracy of 73% com- pared to the other models while Logistic Regression, Bag- ging and Boosting performing comparatively decent.<br />

<b>Experiment 3:</b> In this experiment we were mainly fo- cused on finding out whether the addition of the positive negative ratio of the comments of each movie made any dif- ference in the accuracy of predicting the performance of the movie. We used the movie success rate dataset that con- tained multiple features of a movie and we added the pos- itive negative comment ratio of the YouTube trailer as fea- tures of the movie.<br />
We carried out the experiment in multiple settings to compare the addition of positive negative comment ratio to the dataset:<br />
• Machine Learning Models’ Performance on the initial dataset<br />
• Machine Learning Models’ Performance on the dataset with positive negative comment ratio included<br />
• MachineLearningModels’Performanceonthedataset using IMDB Rating as the classifier without positive negative comment ratio<br />
• MachineLearningModels’Performanceonthedataset using IMDB Rating as the classifier with positive neg- ative comment ratio<br />

<h2><b>Conclusion</b></h2>
From all our experiments we can conclude that YouTube trailer comments alone cannot help in the prediction of the rating(good, average, bad) of the movie. We see this clearly in experiments 1 and 2 where in we changed our approaches and used multiple models to see if a good enough result can achieved. However, these positive and negative comment values can be added to previous models and then be trained to give better accuracy. We also noticed that when the model used the feature "Success" of the dataset as the classification label it performed significantly better than when the model used "IMDB Rating Classification" as the classification la- bel. The IMDB ratings of a movie are subjected to many criteria and not usually the public response to a movie. As our model focuses more on predicting the public response to a movie IMDB Rating might not be the best classifica- tion criteria. We believe if the similar tests were carried out using the "Success" feature as the classification label we might be able to achieve better performance with the ma- chine learning models.